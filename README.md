# AI Model Update Tracker

**Stay updated on the latest changes from Anthropic, OpenAI, and Google AI.**

Automated tracking of Anthropic, GPT, and Gemini model releases, API updates, and feature launches. Delivered as curated weekly summaries with actionable insights.

---

## üìä Latest Updates

> **Last Updated:** 2025-10-16
> **Status:** üöÄ Repository initialized, automation ready

*Weekly summaries will appear here once scraping begins*

---

## üéØ What This Tracks

### Providers (Priority Order)
1. **Anthropic** - AI models and API
2. **OpenAI** - GPT models and API
3. **Google** - Gemini models and API

### Update Categories
- ‚úÖ **Model Releases** - New model families (e.g., GPT-4 ‚Üí GPT-5)
- ‚úÖ **Version Updates** - Model iterations (e.g., GPT-4 ‚Üí GPT-4 Turbo)
- ‚úÖ **API Features** - New capabilities (vision, streaming, function calling)
- ‚úÖ **Pricing Changes** - Cost adjustments
- ‚úÖ **Performance** - Speed/quality improvements
- ‚úÖ **Breaking Changes** - Migration requirements

---

## üîÑ How It Works

### Automated (3x/week)
1. **GitHub Actions** scrapes provider sites (Mon/Wed/Fri @ 09:00 UTC)
2. Raw diffs saved to [`/raw/`](./raw/)
3. **Notification issue** created when changes detected

### Manual (~10 min/week)
1. Review `/raw/YYYY-MM-DD-summary.txt`
2. Paste relevant sections into **your AI assistant**
3. Ask for a summary: *"Summarize these AI model updates in our standard format"*
4. Commit summary to [`/updates/`](./updates/)

### Zero Cost
- **GitHub Actions:** Free tier (2,000 min/month, using ~60)
- **AI Summarization:** Use your existing LLM subscription
- **Total:** $0/month

---

## üìÇ Repository Structure

```
/
‚îú‚îÄ‚îÄ providers/          # Provider tracking templates
‚îÇ   ‚îú‚îÄ‚îÄ anthropic.md    # Anthropic changelog sources
‚îÇ   ‚îú‚îÄ‚îÄ openai.md       # OpenAI changelog sources
‚îÇ   ‚îî‚îÄ‚îÄ google.md       # Google AI changelog sources
‚îú‚îÄ‚îÄ updates/            # Curated weekly summaries
‚îÇ   ‚îî‚îÄ‚îÄ 2025-10-16-summary.md
‚îú‚îÄ‚îÄ raw/                # Automated scrape output
‚îÇ   ‚îú‚îÄ‚îÄ 2025-10-16-anthropic.json
‚îÇ   ‚îú‚îÄ‚îÄ 2025-10-16-openai.json
‚îÇ   ‚îú‚îÄ‚îÄ 2025-10-16-google.json
‚îÇ   ‚îî‚îÄ‚îÄ 2025-10-16-summary.txt
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ scrape.py       # Python scraper
‚îî‚îÄ‚îÄ .github/workflows/
    ‚îî‚îÄ‚îÄ scrape-updates.yml
```

---

## üöÄ Quick Start

### 1. Test the Scraper Locally
```bash
python scripts/scrape.py
```

This will:
- Scrape all three providers
- Save results to `/raw/`
- Output a summary file for review

### 2. Review Raw Output
```bash
cat raw/$(date +%Y-%m-%d)-summary.txt
```

### 3. Summarize with AI Assistant
1. Copy relevant sections from summary file
2. Paste into your preferred LLM (ChatGPT, Gemini, etc.)
3. Ask: *"Summarize these AI model updates. For each change, include: what changed, why it matters, and migration notes if applicable."*

### 4. Commit Your Summary
```bash
# Save the AI-generated summary to updates/
echo "AI summary here" > updates/2025-10-16-summary.md
git add updates/
git commit -m "Weekly summary: 2025-10-16"
git push
```

---

## ü§ñ Automation Setup

The GitHub Action runs automatically, but you can:

### Trigger Manual Scrape
1. Go to **Actions** tab
2. Select **Scrape AI Model Updates**
3. Click **Run workflow**

### Adjust Frequency
Edit `.github/workflows/scrape-updates.yml`:
```yaml
schedule:
  - cron: '0 9 * * 1,3,5'  # Mon/Wed/Fri at 09:00 UTC
```

### Disable Notifications
Remove or comment out the "Create notification issue" step in the workflow.

---

## üìñ Update Format

Each summary follows this template:

```markdown
# Weekly Summary: YYYY-MM-DD

## Anthropic
### [Date] Update Title
**What changed:** Brief description
**Why it matters:** Impact on use cases
**Migration notes:** Breaking changes or action items
**Link:** [Official announcement](URL)

## OpenAI
...

## Google
...
```

---

## üîç Provider Resources

### Anthropic
- [Changelog](https://docs.anthropic.com/en/docs/about-claude/changelog)
- [News](https://www.anthropic.com/news)
- [API Docs](https://docs.anthropic.com)

### OpenAI
- [API Changelog](https://platform.openai.com/docs/changelog)
- [Research Blog](https://openai.com/research)
- [API Docs](https://platform.openai.com/docs)

### Google
- [AI Blog](https://blog.google/technology/ai/)
- [Vertex AI Release Notes](https://cloud.google.com/vertex-ai/docs/release-notes)
- [Gemini API Docs](https://ai.google.dev/docs)

---

## üõ†Ô∏è Maintenance

### Known Limitations
- ‚ö†Ô∏è **OpenAI Bot Detection:** OpenAI may block automated scraping (403 errors)
  - Scraper will continue with other providers
  - Manual fallback: Check [changelog](https://platform.openai.com/docs/changelog) directly
  - Data for Anthropic and Google will still be collected

### When Scraper Breaks
If a provider changes their site structure:

1. Check error in Actions logs
2. Update scraper in `scripts/scrape.py`
3. Test locally: `python scripts/scrape.py`
4. Commit fix

**Expected:** ~2x/year for maintenance

### Adding More Providers
1. Add provider template to `/providers/`
2. Add scraper function to `scripts/scrape.py`
3. Update README

---

## üìä Stats

- **Scraping Frequency:** 3x/week
- **GitHub Actions Usage:** ~5 min/run = 60 min/month (3% of free tier)
- **Manual Effort:** ~10 min/week
- **Cost:** $0/month

---

## ü§ù Contributing

This is a personal tracking repo, but feel free to:
- **Fork** and customize for your own use
- **Open issues** for broken scrapers
- **Suggest** additional providers or categories

---

## üìÑ License

MIT License - Use freely

---

## üí° Why This Exists

AI models are evolving rapidly. Keeping up with Anthropic, GPT, and Gemini updates across blogs, changelogs, and release notes is time-consuming.

**This repo solves that by:**
- ü§ñ Automating the scraping
- üìù Surfacing only what changed
- üß† Using AI-assisted summarization
- üí∞ Costing $0/month

---

**Questions?** Open an issue or check [provider docs](./providers/).
